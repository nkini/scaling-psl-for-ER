{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The setup\n",
    "\n",
    "I am in possession of 6 variations of the CORA dataset for entity resolution.\n",
    "1. Cora-HPI (https://hpi.de/naumann/projects/repeatability/datasets/cora-dataset.html) [7][8]\n",
    "2. Cora-UWash (https://alchemy.cs.washington.edu/data/cora/) [3][4][5][6]\n",
    "3. Cora-McCallum (https://people.cs.umass.edu/~mccallum/data.html) [1]\n",
    "4. Cora-WCohen (http://www.cs.utexas.edu/users/ml/riddle/data.html) [2]\n",
    "5. Cora-CVUT (https://relational.fit.cvut.cz/dataset/CORA, https://sites.google.com/site/semanticbasedregularization/home/software/experiments_on_cora)\n",
    "6. Cora-UMD (http://www.cs.umd.edu/~sen/lbc-proj/LBC.html)\n",
    "\n",
    "The chronology helps in identifying the lineage/development of these variations.\n",
    "\n",
    "**[1] KDD 2000 - McCallum, Nigam, Ungar - Efficient Clustering of High-Dimensional Data Sets with Application to Reference Matching.**\n",
    "\n",
    "\"In order **to evaluate** both the speed and accuracy of our\n",
    "clustering algorithms, we take a subset of the Cora citation\n",
    "data and hand-label it according to its correct clustering.\n",
    "Our labeled data consist of all citations from our collection\n",
    "to papers authored by either Michael Kearns, Robert\n",
    "Schapire or Yoav Freund. We identify these papers by generous\n",
    "substring matching on the author names, and then\n",
    "prune out papers not authored by one of our subjects. In all,\n",
    "this comprises **1916 citations to 121 distinct papers**. About \n",
    "one-quarter of the papers have only one or two reference to\n",
    "them; several papers have many references to them. The\n",
    "most popular paper is cited 108 times.\n",
    "\n",
    "...\n",
    "\n",
    "There are three tunable parameters for the canopies clustering:\n",
    "the tight and loose thresholds for the cheap distance\n",
    "metric, and the stopping point for the Greedy Agglomerative\n",
    "Clustering. We tuned these three parameters on a\n",
    "separate, similarly sized **validation dataset** for the authors\n",
    "Scott Fahlman, Dennis Kibler and Paul Utgoff. The string\n",
    "edit costs for the different operations were set to hand-coded\n",
    "values. Learning and tuning these string edit weights automatically\n",
    "is an area of ongoing research.\"\n",
    "\n",
    "**[2] KDD 2003 - Bilenko, Mooney - Adaptive Duplicate Detection Using Learnable String Similarity Measures**\n",
    "\n",
    "\"Cora is a collection of **1295 distinct citations to 122**\n",
    "Computer Science research papers from the Cora Computer Science\n",
    "research paper search engine. The citations were segmented\n",
    "into multiple fields such as author, title, venue, etc. by an information\n",
    "extraction system, resulting in some crossover noise between\n",
    "the fields.\"\n",
    "\n",
    "**[3] ICML 2005 - Kok, Domingos. Learning the Structure of Markov Logic Networks.**\n",
    "\n",
    "\"We carried out experiments on two publicly available\n",
    "databases: the UW-CSE database used\n",
    "by Richardson and Domingos (2004) (available at\n",
    "http://www.cs.washington.edu/ai/mln), and McCallum's\n",
    "Cora database of computer science citations as segmented\n",
    "by Bilenko and Mooney (2003) (available at\n",
    "http://www.cs.utexas.edu/users/ml/riddle/data/cora.tar.gz).\n",
    "\n",
    "The Cora dataset is a collection of **1295 different citations\n",
    "to 112 computer science research papers**. We used\n",
    "the author, venue, title and year fields. The goal is to\n",
    "determine which pairs of citations refer to the same paper\n",
    "(i.e., to infer the truth values of all groundings of\n",
    "SameCitation(c1; c2)). These values are available in the\n",
    "data. Additionally, we can attempt to deduplicate the author,\n",
    "title and venue strings, and we labeled these manually.\n",
    "We defined predicates for each field that discretize the percentage\n",
    "of words that two strings have in common. For example,\n",
    "WordsInCommonInTitle20%(title1; title2)\n",
    "is true iff the two titles have 0-20% of their words in common.\n",
    "These predicates are always given as evidence, and\n",
    "we do not attempt to predict them. Using typed variables,\n",
    "the total number of possible ground predicates is\n",
    "5,225,411. The database contained a total of 378,589 tuples\n",
    "(ground atoms). A hand-crafted KB for this domain\n",
    "was provided by a colleague; it contains 26 clauses stating\n",
    "regularities like: if two citations are the same, their authors,\n",
    "venues, etc., are the same, and vice-versa; if two fields of\n",
    "the same type have many words in common, they are the\n",
    "same; etc.\"\n",
    "\n",
    "**[4] AAAI 2005 - Singla, Domingos - Discriminative Training of Markov Logic Networks.**\n",
    "\n",
    "\"We carried out experiments on two publiclyavailable\n",
    "databases: the UW-CSE database used\n",
    "by Richardson and Domingos (2004) (available at\n",
    "http://www.cs.washington.edu/ai/mln), and McCallum's\n",
    "Cora database of computer science citations as\n",
    "segmented by Bilenko and Mooney (2003) (available at\n",
    "http://www.cs.utexas.edu/users/ml/riddle/data/cora.tar.gz).\n",
    "\n",
    "The Cora database is a collection of **1295 different\n",
    "citations** to computer science research papers. We cleaned\n",
    "it up by **correcting some labels and filling in missing values.\n",
    "This cleaned-up version contains references to 132 different\n",
    "research papers.** We used the author, venue, and title fields.\n",
    "The goal is to de-duplicate citations, authors and venues\n",
    "(i.e., to determine which pairs of citations, author fields,\n",
    "and venue fields refer to the same underlying paper, author\n",
    "and venue, respectively). We thus defined the equality\n",
    "predicates SameCitation(citation1; citation2),\n",
    "SameAuthor(author1; author2), and SameVenue\n",
    "(venue1; venue2). We also defined an equality predicate\n",
    "for each pair of title field values, i.e., SameTitle\n",
    "(title1; title2). For each field, we defined six predicates\n",
    "testing whether the cosine TF-IDF similarity\n",
    "score (Salton & McGill 1983) of two field values lies in\n",
    "a particular range (0, 00.2, 0.20.4, etc.). For example,\n",
    "TitleTFIDF:4(title1; title2) is true if the titles\n",
    "title1 and title2 have a TF-IDF score in the range\n",
    "(0:2; 0:4], and false otherwise. The TFIDF predicates can\n",
    "be computed directly from the data, and their groundings\n",
    "are the evidence atoms. At inference time, all equality\n",
    "predicates are unknown; we hand-labeled them for training\n",
    "and testing purposes (except for SameCitation, which was\n",
    "provided in the original database). Using typed variables,\n",
    "the total number of possible ground atoms is 401,552. The\n",
    "database contained a total of 82,026 tuples (true ground\n",
    "atoms). We hand-coded a KB for this domain, consisting\n",
    "of 46 clauses stating regularities like: if two citations are\n",
    "the same, their authors, venues, etc., are the same, and\n",
    "vice-versa; if two fields have a high TF-IDF score, they\n",
    "are the same; etc. While these are not valid as categorical\n",
    "logical statements, they capture important probabilistic\n",
    "relationships when incorporated with weights into an MLN.\"\n",
    "\n",
    "**[5] AAAI 2006 - Singla, Domingos - Memory-Efficient Inference in Relational Domains.**\n",
    "\n",
    "\"We used two publicly available citation\n",
    "databases in our experiments: McCallum's Cora database\n",
    "as segmented by Bilenko and Mooney (2003) (available at\n",
    "http://www.cs.utexas.edu/users/ml/riddle/data/cora.tar.gz);\n",
    "and BibServ.org, which combines CiteSeer, DBLP, and\n",
    "user-donated databases. **Cora contains 1295 citations**,\n",
    "extracted from the original Cora database of over 50,000,\n",
    "and BibServ contains approximately half a million citations.\n",
    "We used the user-donated subset of BibServ, with 21,805\n",
    "citations.\n",
    "\n",
    "...\n",
    "\n",
    "We used the **cleaned version of Cora as described in\n",
    "Singla and Domingos (2005).**\"\n",
    "\n",
    "**[6] ICDM 2006 - Singla, Domingos - Entity Resolution with Markov Logic.**\n",
    "\n",
    "\"We used two publicly available citation databases in our\n",
    "experiments: Cora and BibServ.\n",
    "\n",
    "The hand-labeled Cora dataset is provided by McCallum (www.cs.umass.edu/∼mccallum/data/cora-refs.tar.gz)\n",
    "and has previously been used by Bilenko and Mooney\n",
    "and others. This dataset is a collection of **1295 different citations**\n",
    "to computer science research papers from the Cora\n",
    "Computer Science Research Paper Engine. The original dataset contains only unsegmented citation strings. Bilenko\n",
    "and Mooney [3] segmented each citation into fields (author,\n",
    "venue, title, publisher, year, etc.) using an information\n",
    "extraction system. We used this processed version of\n",
    "Cora. We further cleaned it up by correcting some labels.\n",
    "**This cleaned version contains references to 132 different research\n",
    "papers.** We used only the three most informative\n",
    "fields: first author, title and venue (with venue including\n",
    "conferences, journals, workshops, etc.). We compared the\n",
    "performance of the algorithms for the task of de-duplicating\n",
    "citations, authors and venues. For training and testing purposes,\n",
    "we hand-labeled the field pairs. **The labeled data\n",
    "contains references to 50 authors and 103 venues.** After\n",
    "forming canopies, the total number of match decisions was\n",
    "61,177.\"\n",
    "\n",
    "**[7] VLDB 2010 - Draisbach, Naumann - DuDe: The Duplicate Detection Toolkit.**\n",
    "\n",
    "\"A disadvantage of this dataset is the\n",
    "missing unique identifier for each record: A deeper look at\n",
    "the records revealed that the reference ID (the BibTeX key)\n",
    "is unfortunately not always faultless. In particular, we discovered\n",
    "two problems: two references have the same reference\n",
    "ID, but do not represent the same paper.\n",
    "And vice versa, there are references that in fact represent\n",
    "the same paper but have different reference IDs. To make the CORA dataset readable for the DuDe\n",
    "toolkit, we have transformed the three original files into one\n",
    "XML document. Therefore, it was necessary to make minor\n",
    "changes within the new file, e.g., adding closing tags\n",
    "for the references or repairing broken tags. Additionally, we\n",
    "have added a unique identifier for each record, which is a\n",
    "prerequisite to define a gold standard.\"\n",
    "\n",
    "**[8] CIKM 2014 - Heise, Kasneci, Naumann - Estimating the Number and Sizes of Fuzzy-Duplicate Clusters.**\n",
    "\n",
    "\"The CD dataset consists of 750,000 CD records from\n",
    "FreeDB with a semi-automatic gold standard [14] created by\n",
    "combining automatic labeling for easy-to-classify pairs and\n",
    "manual labeling for hard pairs. Because of its many contributors,\n",
    "the dataset contains 55,323 duplicates clusters, which\n",
    "are approximately power law distributed with cluster sizes\n",
    "up to 50. We use it as the main dataset for our evaluation.  \n",
    "\n",
    "A much cleaner dataset is the Customer dataset containing\n",
    "1,039,776 person records including 89,782 artificially\n",
    "polluted duplicate pairs. The dataset was generated by a\n",
    "large industry partner to test (their) duplicate detection algorithms\n",
    "and simulates the integration result of three relatively\n",
    "clean, duplicate-free datasets with a small overlap.  \n",
    "\n",
    "On the other side of the spectrum is the Cora dataset with\n",
    "only **182 clusters in 1878 bibliographic records and a maximum\n",
    "cluster size of 238 records**. It is a real-world dataset\n",
    "with a gold standard [4]. Due to the relatively huge clusters,\n",
    "it tests the boundaries of our method.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now here's the interesting question. \n",
    "\n",
    "Given that our target is a direct comparison of our results with the results in **\"Adaptive Blocking: Learning to Scale Up Record Linkage\" - Bilenko, Kamath, Mooney - ICDM 2006**, and given that the paper does not explicitly point to a link to the dataset used, which version of the dataset should we use?\n",
    "\n",
    "\"The Cora dataset contains **2191 5-field citations to 305\n",
    "computer science papers**. It was obtained by combining\n",
    "the multiple datasets used in [26], and removing records\n",
    "that are exact duplicates. While it is a relatively smallscale\n",
    "dataset, accurate linkage on this dataset requires computationally\n",
    "intensive string similarity functions and bene-\n",
    "fits from collective linkage methods, justifying the need for\n",
    "blocking [4, 26]\"\n",
    "\n",
    "[26] here refers to KDD 2000 - McCallum, Nigam, Ungar. \n",
    "\n",
    "My interpretation of this is that the 'multiple datasets' refer to the evaluation and tuning datasets - a combo of the Freund, Kearns, Schapire data subset with the Fahlman, Kibler, Utgof data subset. What's discomforting about this is the numbers - 2191 citations that refer to 305 papers, vs 1916 referring to 122 papers, vs 182 clusters in 1878 bibliographic records - these numbers seem too erratic to be related.\n",
    "\n",
    "I'm starting to think it isn't wise to try and reproduce the exact numbers from this paper, and just verify comparing the trends. Use the clean VLDB 2010 DuDe dataset. Hmmm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORA-WCohen\n",
    "\n",
    "Oh the hoops I had to jump through to get this pandas readable...\n",
    "Arff -> weka -> save as csv -> replace \\' with nothing in gedit -> open in libreoffice, get the settings for separators and delimiters right -> save as ods -> import in Google Docs spreadsheet -> export as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wcohen = pd.read_csv('data/cora-wcohen/cora.arff4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_wcohen['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_wcohen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cora_wcohen_json = df_wcohen.to_json(orient='records')\n",
    "json.dump(cora_wcohen_json, open('data/cora-wcohen/cora_wcohen.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORA-UWash\n",
    "\n",
    "Analyzed more extensively elsewhere. Statistics produced here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "df_uwash = pd.read_json('data/cora-uwash/cora0+1+2.json')\n",
    "print(len(df_uwash['class_no'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_uwash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(df_uwash.to_json(orient='records'), open('data/cora-uwash/cora_uwash.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drucker1992', 'drucker1992C1', 'freund0000a', 'freund1992a',\n",
       "       'freund1993cC', 'freund1995e', 'freund1996c', 'freund1997a',\n",
       "       'freund1997d', 'goldman1990a', 'goldman1993', 'haussler1988C',\n",
       "       'haussler1994a', 'haussler1994aC2', 'kautz1993', 'kautz1995',\n",
       "       'kearns1994cryp', 'kearns1994d', 'kearns1994e', 'kearns1996a',\n",
       "       'kearns1996b', 'kearns1997b', 'lewis1996', 'littlestone',\n",
       "       'rivest1987d', 'rivest1989', 'rivest1992', 'rivest1992C',\n",
       "       'rivest1994', 'schapire', 'schapire1988', 'schapire1989',\n",
       "       'schapire1990', 'schapire1991C2', 'schapire1992C', 'schapire1994',\n",
       "       'schapire1996', 'schapire1996p', 'schapire1997C', 'schapire1997u',\n",
       "       'schapire1997um', 'schapire1998', 'schapire1998mm', 'auer1995a',\n",
       "       'blum1993', 'cesa', 'cesaR', 'cesaJ', 'cohen1998', 'drucker1992C2',\n",
       "       'feder1995', 'freund1992b', 'freund1993a', 'freund1993b',\n",
       "       'freund1993c', 'freund1995aC', 'freund1995d', 'freund1995f',\n",
       "       'freund1996a', 'freund1996e', 'goldman1993aC', 'haussler1988',\n",
       "       'haussler1991p', 'haussler1992', 'haussler1994', 'haussler1994aC1',\n",
       "       'haussler1996', 'helmbold1995', 'helmbold1995a', 'helmbold1995aC',\n",
       "       'helmbold1997', 'kautz1993C', 'kearns1987', 'kearns1988',\n",
       "       'kearns1988bC', 'kearns1989', 'kearns1992a', 'kearns1992c',\n",
       "       'kearns1993a', 'kearns1993b', 'kearns1993bC', 'kearns1993c',\n",
       "       'kearns1994b', 'bauer1992', 'blum1994', 'cesaC', 'dietterich1996',\n",
       "       'ehrenfeucht1988', 'ehrenfeucht1988C', 'ehrenfeucht1989',\n",
       "       'freund1992aC', 'freund1992c', 'freund1995a', 'freund1995b',\n",
       "       'freund1995c', 'freund1996b', 'freund1996d', 'freund1997b',\n",
       "       'freund1997c', 'goldman1989', 'goldman1990c', 'goldman1991',\n",
       "       'goldman1993a', 'goldman1995', 'haussler1991', 'helmbold1996',\n",
       "       'helmbold1996a', 'helmbold1997c', 'kearns1987b', 'kearns1988b',\n",
       "       'kearns1989a', 'kearns1990', 'kearns1990b', 'kearns1990c',\n",
       "       'kearns1994a', 'kearns1994c', 'kearns1995b', 'kearns1997a',\n",
       "       'kearns1997aC', 'kearns1998', 'kearns1998C', 'kearns1999a',\n",
       "       'kearns1999b', 'rivest1987', 'rivest1993', 'schapire1990C1',\n",
       "       'schapire1990C2', 'schapire1990e', 'schapire1991', 'schapire1991C1',\n",
       "       'schapire1991l', 'schapire1992', 'schapire1993', 'schapire1997'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uwash['class_no'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORA-HPI\n",
    "\n",
    "Hopefully this is the cleanest of the lot and won't require me to make any (!) edits... It is, however, in XML form :/ Used http://www.utilities-online.info/xmltojson/ to convert the xml to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cora_hpi_json_raw = json.load(open('data/cora-hpi/cora-all-id.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1878"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cora_hpi_json_raw['coraRADD']['publication'])\n",
    "# This is a list of publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-id': 'ahlskog1994a',\n",
       " 'author': [{'#text': 'M. Ahlskog', '-id': '199'},\n",
       "  {'#text': ' J. Paloheimo', '-id': '74'},\n",
       "  {'#text': ' H. Stubb', '-id': '64'},\n",
       "  {'#text': ' P. Dyreklev', '-id': '103'},\n",
       "  {'#text': ' M. Fahlman', '-id': '54'}],\n",
       " 'title': ['Inganas', 'and', 'M.R.'],\n",
       " 'venue': {'venue': {'-id': '1',\n",
       "   '-pubid': 'ahlskog1994a',\n",
       "   'date': ' (1994). ',\n",
       "   'name': ['Andersson', ' J Appl. Phys.'],\n",
       "   'vol': '76'}}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a gold standard, this database does leave a little to be desired...\n",
    "# imho, it's great for authors and title, but the venue, date, etc are a tad iffy\n",
    "cora_hpi_json_raw['coraRADD']['publication'][0]\n",
    "# At this point we need to decide which fields to use for our json/dataframe\n",
    "# class : the publication label\n",
    "# authorids : a list of authorids\n",
    "# authors : a list of authors\n",
    "# venue : the name children part of the element\n",
    "# volume\n",
    "# date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue', '-id', '#text', 'author', 'date', 'vol', '-pubid', 'name', 'title'}\n"
     ]
    }
   ],
   "source": [
    "allkeys = set()\n",
    "def myprint(d):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            allkeys.add(k)\n",
    "            myprint(v)\n",
    "    elif isinstance(d, list):\n",
    "        for el in d:\n",
    "            myprint(el)\n",
    "\n",
    "myprint(cora_hpi_json_raw['coraRADD']['publication'])\n",
    "print(allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = []\n",
    "for publication in cora_hpi_json_raw['coraRADD']['publication']:\n",
    "    d = {}\n",
    "    d['class'] = publication['-id']\n",
    "    d['authors'] = []\n",
    "    d['authorids'] = []\n",
    "    \n",
    "    if 'author' in publication: \n",
    "    \n",
    "        if isinstance(publication['author'],list):\n",
    "            for author in publication['author']:\n",
    "                d['authorids'].append(int(author['-id']))\n",
    "                d['authors'].append(author['#text'])\n",
    "        elif isinstance(publication['author'],dict):\n",
    "            d['authorids'].append(int(publication['author']['-id']))\n",
    "            d['authors'].append(publication['author']['#text'])\n",
    "        \n",
    "    if 'title' in publication:\n",
    "        d['title'] = ' '.join(publication['title'])\n",
    "    else:\n",
    "        #print(publication)\n",
    "        d['title'] = ''\n",
    "    \n",
    "    if 'name' in publication['venue']['venue']:\n",
    "        if isinstance(publication['venue']['venue']['name'],list):\n",
    "            d['venue'] = ' '.join(publication['venue']['venue']['name'])\n",
    "        else:\n",
    "            d['venue'] = publication['venue']['venue']['name']\n",
    "    else:\n",
    "        d['venue'] = ''\n",
    "    \n",
    "    if 'vol' in publication['venue']['venue']:\n",
    "        d['volume'] = publication['venue']['venue']['vol']\n",
    "    else:\n",
    "        d['volume'] = ''\n",
    "    \n",
    "    if 'date' in publication['venue']['venue']:\n",
    "        d['date'] = publication['venue']['venue']['date']\n",
    "    else:\n",
    "        d['date'] = ''\n",
    "    \n",
    "    database.append(d)\n",
    "    \n",
    "# That did not go as smoothly as expected :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpi = pd.DataFrame(database)\n",
    "len(df_hpi['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ahlskog1994a', 'asfahl1992a', 'benford1993a', 'benford1994a',\n",
       "       'benford1995a', 'benford1995b', 'brown1992a', 'buth1992a',\n",
       "       'carlson1993a', 'cramer1985a', 'daelemans1995a', 'deb1989a',\n",
       "       'dempster1977a', 'dill1997a', 'dill1997b', 'dutta1988a',\n",
       "       'fahle1981a', 'fahle1991a', 'fahle1992a', 'fahle1993a',\n",
       "       'fahle1995a', 'fahle1997a', 'fahlen1993a', 'fahlman1974a',\n",
       "       'fahlman1979a', 'fahlman1980a', 'fahlman1981a', 'fahlman1981b',\n",
       "       'fahlman1985a', 'fahlman1987a', 'fahlman1988a', 'fahlman1988b',\n",
       "       'fahlman1990a', 'fahlman1991a', 'fahlman1991b', 'fahlman1991c',\n",
       "       'fahlman1993a', 'fahlman1993b', 'fahlman1996a', 'fahln1993a',\n",
       "       'forchheimer1983a', 'frankel1994a', 'hendren1992a', 'herzog1995a',\n",
       "       'hoehfeld1992a', 'knoop1992a', 'knopp1992a', 'kriegel1993a',\n",
       "       'langendoen1992a', 'mcdonald1987a', 'pfahler1997a', 'poggio1992a',\n",
       "       'poggio1992b', 'pope1992a', 'shapiro1980a', 'steele1984a',\n",
       "       'steele1990a', 'sudholt1992a', 'thrun1991a', 'thurn1991a',\n",
       "       'vitek1992a', 'walter1987a', 'weiss1993a', 'white1994a',\n",
       "       'wholey1984a', 'aha1987', 'aha1989', 'aha1991', 'aha1992',\n",
       "       'cheng1996', 'conery1981', 'dasarathy1991', 'datta1992',\n",
       "       'datta1995', 'hall1989', 'hampson1995', 'hu1996', 'kelly1991',\n",
       "       'kibler1978', 'kibler1981', 'kibler1983', 'kibler1985',\n",
       "       'kibler1988', 'kibler1988a', 'kibler1989', 'kibler1991',\n",
       "       'langley1986', 'nilsson1994', 'norvig1992', 'ortega1995',\n",
       "       'pazzani1990', 'porter1986', 'ruby1989', 'ruby1991', 'ruby1991a',\n",
       "       'ruby1992', 'rudy1992', 'skiblics1996', 'standish1976',\n",
       "       'webber1994', 'weber1994', 'conery19xx', 'conery1983', 'conery1985',\n",
       "       'conery1985a', 'kibler1992', 'kibler1993', 'learning1991',\n",
       "       'learning1992', 'ourston1994', 'sklansky1976', 'brodley1992',\n",
       "       'brodley1992b', 'brodley1994', 'brodley1995', 'callan1991',\n",
       "       'callan1991aaai', 'cardie1993', 'caruana1993', 'chapman1987',\n",
       "       'chapman1991', 'clark1993', 'cleeremans1989', 'clouse1992',\n",
       "       'connel1987', 'connell1987', 'craven1993', 'danyluk1993',\n",
       "       'draper1994', 'fawcett1991', 'fawcett1992', 'fayyad1993',\n",
       "       'huffman1993', 'johnson1982', 'jordan1993', 'kaelbling1993',\n",
       "       'mccallum1993', 'mehra1998', 'minton1992', 'mitchell1981',\n",
       "       'mitchell1983', 'mitchell1983ijcai', 'mitchell1993',\n",
       "       'mitchell1993ebl', 'mladenic', 'mladenic1993', 'moss1997',\n",
       "       'musick1992', 'quinlan1993', 'ragavan1993', 'rymon1993',\n",
       "       'safford1993', 'schmill1998', 'schwartz1993', 'stone1977',\n",
       "       'torgo1990', 'torgo1995', 'utgoff1982aaai', 'utgoff1982ml',\n",
       "       'utgoff1983', 'utgoff1984phd', 'utgoff1986book', 'utgoff1986mlii',\n",
       "       'utgoff1987', 'utgoff1988aaai', 'utgoff1988iid', 'utgoff1988pt',\n",
       "       'utgoff1989', 'utgoff1989mlw', 'utgoff1989pt', 'utgoff1989rp',\n",
       "       'utgoff1990', 'utgoff1991aaai', 'utgoff1991lmdt', 'utgoff1994',\n",
       "       'utgoff1995', 'utgoff1996', 'utgoff1996ks', 'utgoff1996mlii',\n",
       "       'utgoff1996va', 'utgoff1997', 'utgoff1997fa', 'utgoff1998',\n",
       "       'yee1990', 'zheng1993'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpi['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A ray of hope\n",
    "\n",
    "Notice how the classes above are different from the classes for UWash. It is likely that df_uwash is McCallum's evaluation data set and df_hpi is McCallum's validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_uwash['class_no'].unique()) | set(df_hpi['class'].unique()))\n",
    "# Oooooh boy. Looking pretty good. 305 vs 319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3173"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_uwash) + len(df_hpi)\n",
    "# Not very good. 2191 vs 3173...\n",
    "# but perhaps \"It was obtained by combining the multiple datasets used in [26], \n",
    "#    and removing records that are exact duplicates\" is a clue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_uwash.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpi_transformed = df_hpi.copy()\n",
    "df_hpi_transformed['authorids'] = df_hpi.authorids.apply(lambda x : ' '.join(map(str,x) if isinstance(x,list) else x))\n",
    "df_hpi_transformed['authors'] = df_hpi.authors.apply(lambda x : ' '.join(x) if isinstance(x,list) else x)\n",
    "df_hpi_transformed['date'] = df_hpi.date.apply(lambda x : ' '.join(x) if isinstance(x,list) else x)\n",
    "df_hpi_transformed['venue'] = df_hpi.venue.apply(lambda x : ' '.join(x) if isinstance(x,list) else x)\n",
    "df_hpi_transformed['volume'] = df_hpi.volume.apply(lambda x : ' '.join(x) if isinstance(x,list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_hpi_transformed\n",
    "len(df_hpi_transformed.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2286"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_hpi_transformed.drop_duplicates()) + len(df_uwash.drop_duplicates())\n",
    "# 2286 vs 2191... Close enough, I suppose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New discoveries\n",
    "\n",
    "Discovered that this df_hpi dataset I've been looking at might be stale, at least in terms of the projects HPI is doing. https://hpi.de/naumann/projects/data-quality-and-cleansing/dude-duplicate-detection.html contains the more recent version of the CORA dataset. What's nice about it is the \"CORA_changes_and_duplicate_groups.txt\" file which enlists changes from the original dataset. What's not nice about it is the absence of author ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
