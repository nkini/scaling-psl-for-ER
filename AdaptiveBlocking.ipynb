{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5849800\n",
    "def tic():\n",
    "    #Homemade version of matlab tic and toc functions\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "\n",
    "def toc():\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        print(\"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\")\n",
    "    else:\n",
    "        print(\"Toc: start time not set\")\n",
    "\n",
    "\n",
    "def read_json_data(filename):\n",
    "    df_adaptive = pd.read_json(filename)\n",
    "    return df_adaptive\n",
    "\n",
    "\n",
    "def define_predicates(data):\n",
    "\n",
    "    P = set()\n",
    "\n",
    "    # For bibliography, use one of the following fields:\n",
    "    # author, title, year, venue, other\n",
    "    # Although it sounds odd, the paper uses every field for every predicate\n",
    "    applicable_fields = ['authors','title','year','venue','other']\n",
    "    \n",
    "    # Contains common integer\n",
    "    name = 'Contains common integer'\n",
    "    h = lambda x    : \"\".join([c if c.isdigit() else ' ' for c in x]).split()\n",
    "    p_= lambda x, y : bool(set(x) & set(y))\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "    \n",
    "    # Contains same or off-by-one integer\n",
    "    name = 'Contains same or off-by-one integer'\n",
    "    h = lambda x    : map(int, \"\".join([c if c.isdigit() else ' ' for c in x]).split())\n",
    "    p_= lambda x, y : bool(set(x) & set(y)) or contains_off_by_one(x,y)\n",
    "    def contains_off_by_one(x, y):\n",
    "        for int1 in x:\n",
    "            for int2 in y:\n",
    "                if abs(int1 - int2) == 1:\n",
    "                    return True\n",
    "        return False\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "    \n",
    "    # Exact match\n",
    "    name = 'Exact match'\n",
    "    h = lambda x    : str(x).strip()\n",
    "    p_= lambda x, y : x == y\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "\n",
    "    # Contains common token\n",
    "    name = 'Contains common token'\n",
    "    h = lambda x    : str(x).strip().split()\n",
    "    p_= lambda x, y : bool(set(x) & set(y))\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "\n",
    "    # Same 3 first characters\n",
    "    name = 'Same 3 first chars'\n",
    "    h = lambda x    : str(x).strip()\n",
    "    p_= lambda x, y : x[:3] == y[:3]\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "\n",
    "    # Same 5 first characters\n",
    "    name = 'Same 5 first chars'\n",
    "    h = lambda x    : str(x).strip()\n",
    "    p_= lambda x, y : x[:5] == y[:5]\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "\n",
    "    # Same 7 first characters\n",
    "    name = 'Same 7 first chars'\n",
    "    h = lambda x    : str(x).strip()\n",
    "    p_= lambda x, y : x[:7] == y[:7]\n",
    "    for p in apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "        P.add(p)\n",
    "    \n",
    "    return P\n",
    "\n",
    "\n",
    "'''\n",
    "Here's a potential data structure for a predicate:\n",
    "\n",
    "class Predicate:\n",
    "    name: a short english definition\n",
    "    field: the field to which to apply\n",
    "    h() : an indexing function\n",
    "    p() : an equality function\n",
    "    pairs_covered : a list of the pairs for which p() returns 1\n",
    "    num_pos_pairs_covered() : should return the count of pairs_covered that are 1/Pos/True  in pair_labels\n",
    "    num_neg_pairs_covered() : should return the count of pairs_covered that are 0/Neg/False in pair_labels\n",
    "    weight() : get set cover weight\n",
    "'''\n",
    "class Predicate:\n",
    "\n",
    "    def __init__(self, name, h, p, field, data):\n",
    "        print(\"processing for predicate ({}), field ({})\".format(name,field))\n",
    "        self.name = name\n",
    "        self.h = h\n",
    "        self.p = p\n",
    "        self.field = field\n",
    "        self.pairs_covered = self._get_pairs_covered(data)\n",
    "\n",
    "    def _get_pairs_covered(self, data):\n",
    "        newcol = '({})_{}'.format(self.name, self.field)\n",
    "        data[newcol] = data[self.field].apply(self.h)\n",
    "        data['tmpkey'] = 1\n",
    "        cols = ['id', newcol, 'tmpkey']\n",
    "        merged = pd.merge(data[cols], data[cols], on='tmpkey')\\\n",
    "                   .drop('tmpkey',axis=1)\\\n",
    "                   .rename(columns={newcol+'_x':'x',newcol+'_y':'y'})\n",
    "        f = lambda row : self.p(row['x'],row['y'])\n",
    "        return merged.apply(f, axis=1)\n",
    "\n",
    "    def num_pos_pairs_covered(self, pair_labels, active_pairs):\n",
    "        return (self.pairs_covered & pair_labels & active_pairs).value_counts()[True]\n",
    "    \n",
    "    def get_pos_pairs_set(self, pair_labels, active_pairs):\n",
    "        return set([index for index, is_true in self.pairs_covered & pair_labels & active_pairs if is_true])\n",
    "    \n",
    "    def num_neg_pairs_covered(self, pair_labels, active_pairs):\n",
    "        counts = (p.pairs_covered & ~pair_labels & active_pairs).value_counts()\n",
    "        if True in counts:\n",
    "            return counts[True]\n",
    "        else:\n",
    "            print(\"Predicate {} apparently covers 0 negative pairs\".format(self))\n",
    "            return 0\n",
    "    \n",
    "    def set_weight(self, pair_labels, active_pairs):\n",
    "        self.weight = self.num_neg_pairs_covered(pair_labels, active_pairs)\n",
    "    \n",
    "    def covers(self, pair_index):\n",
    "        return self.pairs_covered[pair_index]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}, field: {}'.format(self.name, self.field)\n",
    "\n",
    "\n",
    "def apply_predicate_to_data(name, h, p_, applicable_fields, data):\n",
    "    for field in applicable_fields:\n",
    "        tic()\n",
    "        p = Predicate(name, h, p_, field, data)\n",
    "        yield p\n",
    "        toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the number of positive pairs covered by predicates\n",
    "def B_(predicates):\n",
    "    global pair_labels\n",
    "    result = pair_labels.copy()\n",
    "    result[:] = False\n",
    "    for p in predicates:\n",
    "        result = result | p.pairs_covered\n",
    "    return (result & pair_labels)\n",
    "\n",
    "def R_(predicates):\n",
    "    global pair_labels\n",
    "    result = pair_labels.copy()\n",
    "    result = False\n",
    "    for p in predicates:\n",
    "        result = result | p.pairs_covered\n",
    "    return (result & ~pair_labels)\n",
    "\n",
    "def lenR(predicates):\n",
    "    R = R_(predicates)\n",
    "    return R.value_counts()[True]\n",
    "\n",
    "def lenB(predicates):\n",
    "    B = B_(predicates)\n",
    "    return B.value_counts()[True]\n",
    "\n",
    "# Returns the number of predicates in P that cover each pair_label\n",
    "def deg(pair_labels, P):\n",
    "    result = pair_labels.copy()\n",
    "    result[:] = 0\n",
    "    for p in P:\n",
    "        result = result + p.pairs_covered.astype(int)\n",
    "    return result\n",
    "\n",
    "def get_t_greedy(P, active_pairs, pair_labels):\n",
    "    b_by_w_best = float('-inf')\n",
    "    best_p = None\n",
    "    for p in P:\n",
    "        b = p.num_pos_pairs_covered(pair_labels, active_pairs)\n",
    "        w = p.weight\n",
    "        if b/w > b_by_w_best:\n",
    "            best_p = p\n",
    "            b_by_w_best = b/w\n",
    "    return p.pairs_covered, p.get_pos_pairs_set(pair_labels, active_pairs)\n",
    "\n",
    "\n",
    "def make_inactive(active_pairs, set_of_indices_to_deactivate):\n",
    "    for index, label in enumerate(active_pairs):\n",
    "        if index in set_of_indices_to_deactivate:\n",
    "            active_pairs[index] = False\n",
    "            \n",
    "def r(p):\n",
    "    global active_pairs, pair_labels\n",
    "    counts = (p.pairs_covered & ~pair_labels & active_pairs).value_counts()\n",
    "    if True in counts:\n",
    "        return counts[True]\n",
    "    else:\n",
    "        print(\"Predicate {} apparently covers 0 negative pairs\".format(p))\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_disjunctive_blocking(B, R, P_orig, epsilon, eta, active_pairs, pair_labels):\n",
    "    \n",
    "    # Method:\n",
    "    # 1. Discard from P all predicates p for which r(p) >= eta'\n",
    "    P = set([p for p in P_orig if r(p) <= eta])\n",
    "    print('{} predicates discarded, {} retained'.format(len(P_orig)-len(P), len(P)))\n",
    "\n",
    "    # 2. Check if cover is feasible\n",
    "    lenBP = lenB(P)\n",
    "    if len(B) - lenBP > epsilon:\n",
    "        print(\"Cover is not feasible, eta too low\")\n",
    "        return P\n",
    "    print(\"Cover is feaisble, |B(P)| = {}\".format(lenBP))\n",
    "\n",
    "    # 3. Set gamma (the unit for it is probably number of predicates \n",
    "    #                  (though it seems more like root num predicates))\n",
    "    beta = len(B)\n",
    "    gamma = math.sqrt(t/math.log(beta))\n",
    "    print(\"Gamma set to {}\".format(gamma))\n",
    "\n",
    "    # 4. Discard all r in R covered by more than gamma predicates\n",
    "    degrees = deg(pair_labels, P)\n",
    "    print(\"Calculated the degree of P\")\n",
    "    R_discard = set([r for r in R if degrees[r] > gamma])\n",
    "    make_inactive(active_pairs, R_discard)\n",
    "    R = R - R_discard\n",
    "    print('{} negative pairs discarded'.format(len(R_discard)))\n",
    "\n",
    "    # 5. Construct an instance of wtd cover set\n",
    "    # This will be done differently given the current implementation\n",
    "    for p in P:\n",
    "        # TODO: Remove after predicate class is re-init\n",
    "        p.weight = r(p)\n",
    "        #p.set_weight(pair_labels, active_pairs)\n",
    "    print('Weights for remaining predicates have been set')\n",
    "\n",
    "    # 6. Initialize T*, for us it will really be equal to P*\n",
    "    T_star = set()\n",
    "\n",
    "    # 7. \n",
    "    while len(B) >= epsilon:\n",
    "        # 8. select the t in T that maximizes b(t)/w(t)\n",
    "        # TODO: what is get_t_greedy()?\n",
    "        B_t, p = get_t_greedy(P, active_pairs, pair_labels)\n",
    "        print(\"Chose {} by the greedy algorithm. It covers {} new positive pairs\".format(p))\n",
    "\n",
    "        # 9. Remove the covered pairs from B\n",
    "        len_prev = len(B)\n",
    "        B = B - B_t\n",
    "        len_now = len(B)\n",
    "        make_inactive(active_pairs, B_t)\n",
    "        print('New pairs added to covered set'.format(len_prev - len_now))\n",
    "\n",
    "        # 10. Add the predicate to T*\n",
    "        T_star.add(p)\n",
    "        \n",
    "        # Missing step? Remove p from P\n",
    "        P.remove(p)\n",
    "\n",
    "    # 11. Return the P* corresponding to T*\n",
    "    return T_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed labels\n",
      "146128 pairs are true out of a total of 3526884\n"
     ]
    }
   ],
   "source": [
    "data = read_json_data('data/df_adaptive.json')\n",
    "data['id'] = data.index\n",
    "data['tmpkey'] = 1\n",
    "cols = ['id', 'class', 'tmpkey']\n",
    "merged = pd.merge(data[cols], data[cols], on='tmpkey')\\\n",
    "           .drop('tmpkey',axis=1)\n",
    "pair_labels = merged.apply(lambda row : row['class_x'] ==  row['class_y'], axis=1)\n",
    "print(\"Computed labels\")\n",
    "print(\"{} pairs are true out of a total of {}\".format(pair_labels.value_counts()[True], len(pair_labels)))\n",
    "\n",
    "active_pairs = pair_labels.copy()\n",
    "active_pairs[:] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed labels\n",
      "146128 pairs are true out of a total of 3526884\n",
      "processing for predicate (Contains common integer), field (authors)\n",
      "Elapsed time is 66.20941519737244 seconds.\n",
      "processing for predicate (Contains common integer), field (title)\n",
      "Elapsed time is 66.61799788475037 seconds.\n",
      "processing for predicate (Contains common integer), field (year)\n",
      "Elapsed time is 66.68908071517944 seconds.\n",
      "processing for predicate (Contains common integer), field (venue)\n",
      "Elapsed time is 65.87133002281189 seconds.\n",
      "processing for predicate (Contains common integer), field (other)\n",
      "Elapsed time is 66.13545560836792 seconds.\n",
      "processing for predicate (Contains same or off-by-one integer), field (authors)\n",
      "Elapsed time is 66.50931978225708 seconds.\n",
      "processing for predicate (Contains same or off-by-one integer), field (title)\n",
      "Elapsed time is 66.53623461723328 seconds.\n",
      "processing for predicate (Contains same or off-by-one integer), field (year)\n",
      "Elapsed time is 69.06398224830627 seconds.\n",
      "processing for predicate (Contains same or off-by-one integer), field (venue)\n",
      "Elapsed time is 67.55611276626587 seconds.\n",
      "processing for predicate (Contains same or off-by-one integer), field (other)\n",
      "Elapsed time is 67.67442798614502 seconds.\n",
      "processing for predicate (Exact match), field (authors)\n",
      "Elapsed time is 57.03979229927063 seconds.\n",
      "processing for predicate (Exact match), field (title)\n",
      "Elapsed time is 57.24500918388367 seconds.\n",
      "processing for predicate (Exact match), field (year)\n",
      "Elapsed time is 57.22207427024841 seconds.\n",
      "processing for predicate (Exact match), field (venue)\n",
      "Elapsed time is 56.72472262382507 seconds.\n",
      "processing for predicate (Exact match), field (other)\n",
      "Elapsed time is 56.89485311508179 seconds.\n",
      "processing for predicate (Contains common token), field (authors)\n",
      "Elapsed time is 68.63546419143677 seconds.\n",
      "processing for predicate (Contains common token), field (title)\n",
      "Elapsed time is 68.67941904067993 seconds.\n",
      "processing for predicate (Contains common token), field (year)\n",
      "Elapsed time is 66.72725367546082 seconds.\n",
      "processing for predicate (Contains common token), field (venue)\n",
      "Elapsed time is 67.73253583908081 seconds.\n",
      "processing for predicate (Contains common token), field (other)\n",
      "Elapsed time is 67.51474857330322 seconds.\n",
      "processing for predicate (Same 3 first chars), field (authors)\n",
      "Elapsed time is 60.872958183288574 seconds.\n",
      "processing for predicate (Same 3 first chars), field (title)\n",
      "Elapsed time is 59.968772649765015 seconds.\n",
      "processing for predicate (Same 3 first chars), field (year)\n",
      "Elapsed time is 58.39797568321228 seconds.\n",
      "processing for predicate (Same 3 first chars), field (venue)\n",
      "Elapsed time is 58.175211668014526 seconds.\n",
      "processing for predicate (Same 3 first chars), field (other)\n",
      "Elapsed time is 58.228042125701904 seconds.\n",
      "processing for predicate (Same 5 first chars), field (authors)\n",
      "Elapsed time is 59.4298141002655 seconds.\n",
      "processing for predicate (Same 5 first chars), field (title)\n",
      "Elapsed time is 58.90334486961365 seconds.\n",
      "processing for predicate (Same 5 first chars), field (year)\n",
      "Elapsed time is 58.691712379455566 seconds.\n",
      "processing for predicate (Same 5 first chars), field (venue)\n",
      "Elapsed time is 58.12829375267029 seconds.\n",
      "processing for predicate (Same 5 first chars), field (other)\n",
      "Elapsed time is 57.4554877281189 seconds.\n",
      "processing for predicate (Same 7 first chars), field (authors)\n",
      "Elapsed time is 59.104820251464844 seconds.\n",
      "processing for predicate (Same 7 first chars), field (title)\n",
      "Elapsed time is 59.957419872283936 seconds.\n",
      "processing for predicate (Same 7 first chars), field (year)\n",
      "Elapsed time is 59.35359025001526 seconds.\n",
      "processing for predicate (Same 7 first chars), field (venue)\n",
      "Elapsed time is 59.53068733215332 seconds.\n",
      "processing for predicate (Same 7 first chars), field (other)\n",
      "Elapsed time is 59.17853784561157 seconds.\n"
     ]
    }
   ],
   "source": [
    "P = define_predicates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_labels_orig = pair_labels.copy()\n",
    "active_pairs_orig = active_pairs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_labels = pair_labels_orig.copy()\n",
    "active_pairs = active_pairs_orig.copy()\n",
    "\n",
    "# coreferent records, represented as indices to the pair_labels Series\n",
    "B = set([index for index, label in enumerate(pair_labels) if label])\n",
    "\n",
    "# non-coreferent records\n",
    "R = set([index for index, label in enumerate(pair_labels) if not label])\n",
    "\n",
    "epsilon = int(len(B) * .50)    # max uncovered coref pairs\n",
    "eta  = len(R)    # max pairs any predicate may cover\n",
    "beta = len(B)    # Number of coreferent pairs\n",
    "rho  = len(R)    # Number of non-coreferent pairs\n",
    "t    = len(P)    # Number of predicates under consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "0 predicates discarded, 35 retained\n",
      "Cover is feaisble, |B(P)| = 146118\n",
      "Gamma set to 1.715545424653564\n",
      "Calculated the degree of P\n",
      "2629256 negative pairs discarded\n",
      "Predicate Same 7 first chars apparently covers 0 negative pairs\n",
      "Predicate Contains common integer apparently covers 0 negative pairs\n",
      "Predicate Exact match apparently covers 0 negative pairs\n",
      "Predicate Exact match apparently covers 0 negative pairs\n",
      "Predicate Exact match apparently covers 0 negative pairs\n",
      "Predicate Same 7 first chars apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Same 7 first chars apparently covers 0 negative pairs\n",
      "Predicate Contains common integer apparently covers 0 negative pairs\n",
      "Predicate Same 5 first chars apparently covers 0 negative pairs\n",
      "Predicate Same 5 first chars apparently covers 0 negative pairs\n",
      "Predicate Same 7 first chars apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Same 5 first chars apparently covers 0 negative pairs\n",
      "Predicate Contains common integer apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Exact match apparently covers 0 negative pairs\n",
      "Predicate Same 7 first chars apparently covers 0 negative pairs\n",
      "Predicate Exact match apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Contains common token apparently covers 0 negative pairs\n",
      "Predicate Same 5 first chars apparently covers 0 negative pairs\n",
      "Predicate Contains same or off-by-one integer apparently covers 0 negative pairs\n",
      "Predicate Same 5 first chars apparently covers 0 negative pairs\n",
      "Weights for remaining predicates have been set\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-0830a17930ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mP_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_disjunctive_blocking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactive_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-148-4842aca23573>\u001b[0m in \u001b[0;36mdo_disjunctive_blocking\u001b[1;34m(B, R, P_orig, epsilon, eta, active_pairs, pair_labels)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# 8. select the t in T that maximizes b(t)/w(t)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# TODO: what is get_t_greedy()?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mB_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_t_greedy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactive_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Chose {} by the greedy algorithm. It covers {} new positive pairs\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-145-e7976572a833>\u001b[0m in \u001b[0;36mget_t_greedy\u001b[1;34m(P, active_pairs, pair_labels)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mbest_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_pos_pairs_covered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactive_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mb_by_w_best\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-8fa7e1fff1d8>\u001b[0m in \u001b[0;36mnum_pos_pairs_covered\u001b[1;34m(self, pair_labels, active_pairs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnum_pos_pairs_covered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactive_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairs_covered\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mpair_labels\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mactive_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_pos_pairs_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactive_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/soe/nkini/.local/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/soe/nkini/.local/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1979\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 1980\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   1981\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1982\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3332)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3035)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "P_star = do_disjunctive_blocking(B, R, P, epsilon, eta, active_pairs, pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, label in enumerate(active_pairs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
